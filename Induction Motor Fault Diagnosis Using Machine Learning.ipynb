{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aff7bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Block_1  Block_2  Block_3  Block_4  Block_5  Block_6  Block_7  Block_8  \\\n",
      "0      2.3309   2.3309   2.3309   2.3309   2.3309   2.3309   2.3309   2.3309   \n",
      "1      2.7228   2.7228   2.7228   2.7228   2.7228   2.7228   2.7228   2.7228   \n",
      "2      2.9524   2.9524   2.9524   2.9524   2.9524   2.9524   2.9524   2.9524   \n",
      "3      2.1111   2.1111   2.1111   2.1111   2.1111   2.1111   2.1111   2.1111   \n",
      "4      2.1282   2.1282   2.1282   2.1282   2.1282   2.1282   2.1282   2.1282   \n",
      "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "3861   2.4603   2.4530   2.4530   2.4530   2.4530   2.4530   2.4530   2.4530   \n",
      "3862   2.3712   2.3712   2.3712   2.3712   2.3712   2.3712   2.3712   2.3712   \n",
      "3863   2.3065   2.3065   2.3065   2.3065   2.3065   2.3065   2.3065   2.3065   \n",
      "3864   2.2552   2.2552   2.2552   2.2552   2.2552   2.2552   2.2552   2.2552   \n",
      "3865   2.2479   2.2479   2.2479   2.2479   2.2479   2.2479   2.2479   2.2479   \n",
      "\n",
      "      Block_9  Block_10  ...  Block_992  Block_993  Block_994  Block_995  \\\n",
      "0      2.3309    2.3309  ...     2.7228     2.7228     2.7228     2.7228   \n",
      "1      2.7228    2.7228  ...     2.9524     2.9524     2.9524     2.9524   \n",
      "2      2.9524    2.9524  ...     2.1111     2.1111     2.1111     2.1111   \n",
      "3      2.1111    2.1111  ...     2.1282     2.1282     2.1282     2.1282   \n",
      "4      2.1282    2.1282  ...     2.9805     2.9805     2.9805     2.9805   \n",
      "...       ...       ...  ...        ...        ...        ...        ...   \n",
      "3861   2.4530    2.4530  ...     2.3712     2.3712     2.3712     2.3712   \n",
      "3862   2.3712    2.3712  ...     2.3065     2.3065     2.3065     2.3065   \n",
      "3863   2.3065    2.3065  ...     2.2552     2.2552     2.2552     2.2552   \n",
      "3864   2.2552    2.2552  ...     2.2466     2.2466     2.2466     2.2466   \n",
      "3865   2.2479    2.2479  ...     2.2894     2.2894     2.2894     2.2894   \n",
      "\n",
      "      Block_996  Block_997  Block_998  Block_999  Block_1000     Label  \n",
      "0        2.7228     2.7228     2.7228     2.7228      2.7228  0.7inner  \n",
      "1        2.9524     2.9524     2.9524     2.9524      2.9524  0.7inner  \n",
      "2        2.1111     2.1111     2.1111     2.1111      2.1111  0.7inner  \n",
      "3        2.1282     2.1282     2.1282     2.1282      2.1282  0.7inner  \n",
      "4        3.0024     3.0024     3.0024     3.0024      3.0024  0.7inner  \n",
      "...         ...        ...        ...        ...         ...       ...  \n",
      "3861     2.3712     2.3712     2.3712     2.3712      2.3712   healthy  \n",
      "3862     2.3065     2.3065     2.3065     2.3065      2.3065   healthy  \n",
      "3863     2.2552     2.2552     2.2552     2.2552      2.2552   healthy  \n",
      "3864     2.2466     2.2466     2.2466     2.2466      2.2466   healthy  \n",
      "3865     2.2894     2.2894     2.2894     2.2894      2.2894   healthy  \n",
      "\n",
      "[3866 rows x 1001 columns]\n",
      "(3866, 1001)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to your root folder\n",
    "root_folder = r\"C:\\Users\\asfam\\OneDrive\\Desktop\\ml assignment\\abc\"\n",
    "\n",
    "# Get the list of folders within the root folder\n",
    "subfolders = [f.path for f in os.scandir(root_folder) if f.is_dir()]\n",
    "\n",
    "# Create an empty DataFrame to store the reshaped data\n",
    "combined_reshaped_data = pd.DataFrame()\n",
    "\n",
    "# Define the maximum number of instances to take from each dataset\n",
    "max_instances = 100000\n",
    "\n",
    "# Loop through each subfolder and read each dataset into a DataFrame\n",
    "for subfolder in subfolders:\n",
    "    files = os.listdir(subfolder)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subfolder, file)\n",
    "        # Read only the 'Current-A' column and limit to 100,000 instances\n",
    "        data = pd.read_csv(file_path, usecols=[' Current-A'], nrows=max_instances)\n",
    "        \n",
    "        # Transpose the DataFrame to have a single row\n",
    "        transposed_current_a = data.transpose()\n",
    "\n",
    "        # Reshape the transposed \"Current-A\" column into blocks of 1000 columns for each row\n",
    "        block_size = 1000\n",
    "        num_blocks = transposed_current_a.shape[1] // block_size\n",
    "        reshaped_current_a = transposed_current_a.iloc[:, :num_blocks * block_size].values.reshape(-1, block_size)\n",
    "\n",
    "        # Create a DataFrame from the reshaped \"Current-A\" column\n",
    "        reshaped_current_a_df = pd.DataFrame(reshaped_current_a, columns=[f'Block_{i+1}' for i in range(block_size)])\n",
    "\n",
    "        # Extract file name without extension from the full file path\n",
    "        file_name_without_extension = os.path.splitext(file)[0]\n",
    "\n",
    "        # Extract label from file name before the '-' symbol\n",
    "        label = file_name_without_extension.split('-')[0]\n",
    "\n",
    "        # Add a new column 'Label' with the corresponding label for each row\n",
    "        reshaped_current_a_df['Label'] = label\n",
    "\n",
    "        # Append the reshaped data to the combined DataFrame\n",
    "        combined_reshaped_data = pd.concat([combined_reshaped_data, reshaped_current_a_df], ignore_index=True)\n",
    "\n",
    "        \n",
    "# Save the combined reshaped DataFrame to a new CSV file\n",
    "output_file_path_reshaped = r'C:\\Users\\asfam\\OneDrive\\Desktop\\ml assignment\\combined_reshaped_data.csv'\n",
    "combined_reshaped_data.to_csv(output_file_path_reshaped, index=False)\n",
    "\n",
    "# Display the combined reshaped DataFrame\n",
    "print(combined_reshaped_data)\n",
    "print(combined_reshaped_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5fcb5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Block_1</th>\n",
       "      <th>Block_2</th>\n",
       "      <th>Block_3</th>\n",
       "      <th>Block_4</th>\n",
       "      <th>Block_5</th>\n",
       "      <th>Block_6</th>\n",
       "      <th>Block_7</th>\n",
       "      <th>Block_8</th>\n",
       "      <th>Block_9</th>\n",
       "      <th>Block_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Block_992</th>\n",
       "      <th>Block_993</th>\n",
       "      <th>Block_994</th>\n",
       "      <th>Block_995</th>\n",
       "      <th>Block_996</th>\n",
       "      <th>Block_997</th>\n",
       "      <th>Block_998</th>\n",
       "      <th>Block_999</th>\n",
       "      <th>Block_1000</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>0.7inner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>0.7inner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>0.7inner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>0.7inner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9805</td>\n",
       "      <td>2.9805</td>\n",
       "      <td>2.9805</td>\n",
       "      <td>2.9805</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>0.7inner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>2.4603</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3866 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Block_1  Block_2  Block_3  Block_4  Block_5  Block_6  Block_7  Block_8  \\\n",
       "0      2.3309   2.3309   2.3309   2.3309   2.3309   2.3309   2.3309   2.3309   \n",
       "1      2.7228   2.7228   2.7228   2.7228   2.7228   2.7228   2.7228   2.7228   \n",
       "2      2.9524   2.9524   2.9524   2.9524   2.9524   2.9524   2.9524   2.9524   \n",
       "3      2.1111   2.1111   2.1111   2.1111   2.1111   2.1111   2.1111   2.1111   \n",
       "4      2.1282   2.1282   2.1282   2.1282   2.1282   2.1282   2.1282   2.1282   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3861   2.4603   2.4530   2.4530   2.4530   2.4530   2.4530   2.4530   2.4530   \n",
       "3862   2.3712   2.3712   2.3712   2.3712   2.3712   2.3712   2.3712   2.3712   \n",
       "3863   2.3065   2.3065   2.3065   2.3065   2.3065   2.3065   2.3065   2.3065   \n",
       "3864   2.2552   2.2552   2.2552   2.2552   2.2552   2.2552   2.2552   2.2552   \n",
       "3865   2.2479   2.2479   2.2479   2.2479   2.2479   2.2479   2.2479   2.2479   \n",
       "\n",
       "      Block_9  Block_10  ...  Block_992  Block_993  Block_994  Block_995  \\\n",
       "0      2.3309    2.3309  ...     2.7228     2.7228     2.7228     2.7228   \n",
       "1      2.7228    2.7228  ...     2.9524     2.9524     2.9524     2.9524   \n",
       "2      2.9524    2.9524  ...     2.1111     2.1111     2.1111     2.1111   \n",
       "3      2.1111    2.1111  ...     2.1282     2.1282     2.1282     2.1282   \n",
       "4      2.1282    2.1282  ...     2.9805     2.9805     2.9805     2.9805   \n",
       "...       ...       ...  ...        ...        ...        ...        ...   \n",
       "3861   2.4530    2.4530  ...     2.3712     2.3712     2.3712     2.3712   \n",
       "3862   2.3712    2.3712  ...     2.3065     2.3065     2.3065     2.3065   \n",
       "3863   2.3065    2.3065  ...     2.2552     2.2552     2.2552     2.2552   \n",
       "3864   2.2552    2.2552  ...     2.2466     2.2466     2.2466     2.2466   \n",
       "3865   2.2479    2.2479  ...     2.2894     2.2894     2.2894     2.2894   \n",
       "\n",
       "      Block_996  Block_997  Block_998  Block_999  Block_1000     Label  \n",
       "0        2.7228     2.7228     2.7228     2.7228      2.7228  0.7inner  \n",
       "1        2.9524     2.9524     2.9524     2.9524      2.9524  0.7inner  \n",
       "2        2.1111     2.1111     2.1111     2.1111      2.1111  0.7inner  \n",
       "3        2.1282     2.1282     2.1282     2.1282      2.1282  0.7inner  \n",
       "4        3.0024     3.0024     3.0024     3.0024      3.0024  0.7inner  \n",
       "...         ...        ...        ...        ...         ...       ...  \n",
       "3861     2.3712     2.3712     2.3712     2.3712      2.3712   healthy  \n",
       "3862     2.3065     2.3065     2.3065     2.3065      2.3065   healthy  \n",
       "3863     2.2552     2.2552     2.2552     2.2552      2.2552   healthy  \n",
       "3864     2.2466     2.2466     2.2466     2.2466      2.2466   healthy  \n",
       "3865     2.2894     2.2894     2.2894     2.2894      2.2894   healthy  \n",
       "\n",
       "[3866 rows x 1001 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"combined_reshaped_data.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f1717e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Block_1</th>\n",
       "      <th>Block_2</th>\n",
       "      <th>Block_3</th>\n",
       "      <th>Block_4</th>\n",
       "      <th>Block_5</th>\n",
       "      <th>Block_6</th>\n",
       "      <th>Block_7</th>\n",
       "      <th>Block_8</th>\n",
       "      <th>Block_9</th>\n",
       "      <th>Block_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Block_992</th>\n",
       "      <th>Block_993</th>\n",
       "      <th>Block_994</th>\n",
       "      <th>Block_995</th>\n",
       "      <th>Block_996</th>\n",
       "      <th>Block_997</th>\n",
       "      <th>Block_998</th>\n",
       "      <th>Block_999</th>\n",
       "      <th>Block_1000</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>2.3309</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>2.7228</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>2.9524</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9805</td>\n",
       "      <td>2.9805</td>\n",
       "      <td>2.9805</td>\n",
       "      <td>2.9805</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>3.0024</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>2.4603</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>2.2466</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3866 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Block_1  Block_2  Block_3  Block_4  Block_5  Block_6  Block_7  Block_8  \\\n",
       "0      2.3309   2.3309   2.3309   2.3309   2.3309   2.3309   2.3309   2.3309   \n",
       "1      2.7228   2.7228   2.7228   2.7228   2.7228   2.7228   2.7228   2.7228   \n",
       "2      2.9524   2.9524   2.9524   2.9524   2.9524   2.9524   2.9524   2.9524   \n",
       "3      2.1111   2.1111   2.1111   2.1111   2.1111   2.1111   2.1111   2.1111   \n",
       "4      2.1282   2.1282   2.1282   2.1282   2.1282   2.1282   2.1282   2.1282   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3861   2.4603   2.4530   2.4530   2.4530   2.4530   2.4530   2.4530   2.4530   \n",
       "3862   2.3712   2.3712   2.3712   2.3712   2.3712   2.3712   2.3712   2.3712   \n",
       "3863   2.3065   2.3065   2.3065   2.3065   2.3065   2.3065   2.3065   2.3065   \n",
       "3864   2.2552   2.2552   2.2552   2.2552   2.2552   2.2552   2.2552   2.2552   \n",
       "3865   2.2479   2.2479   2.2479   2.2479   2.2479   2.2479   2.2479   2.2479   \n",
       "\n",
       "      Block_9  Block_10  ...  Block_992  Block_993  Block_994  Block_995  \\\n",
       "0      2.3309    2.3309  ...     2.7228     2.7228     2.7228     2.7228   \n",
       "1      2.7228    2.7228  ...     2.9524     2.9524     2.9524     2.9524   \n",
       "2      2.9524    2.9524  ...     2.1111     2.1111     2.1111     2.1111   \n",
       "3      2.1111    2.1111  ...     2.1282     2.1282     2.1282     2.1282   \n",
       "4      2.1282    2.1282  ...     2.9805     2.9805     2.9805     2.9805   \n",
       "...       ...       ...  ...        ...        ...        ...        ...   \n",
       "3861   2.4530    2.4530  ...     2.3712     2.3712     2.3712     2.3712   \n",
       "3862   2.3712    2.3712  ...     2.3065     2.3065     2.3065     2.3065   \n",
       "3863   2.3065    2.3065  ...     2.2552     2.2552     2.2552     2.2552   \n",
       "3864   2.2552    2.2552  ...     2.2466     2.2466     2.2466     2.2466   \n",
       "3865   2.2479    2.2479  ...     2.2894     2.2894     2.2894     2.2894   \n",
       "\n",
       "      Block_996  Block_997  Block_998  Block_999  Block_1000      Label  \n",
       "0        2.7228     2.7228     2.7228     2.7228      2.7228  unhealthy  \n",
       "1        2.9524     2.9524     2.9524     2.9524      2.9524  unhealthy  \n",
       "2        2.1111     2.1111     2.1111     2.1111      2.1111  unhealthy  \n",
       "3        2.1282     2.1282     2.1282     2.1282      2.1282  unhealthy  \n",
       "4        3.0024     3.0024     3.0024     3.0024      3.0024  unhealthy  \n",
       "...         ...        ...        ...        ...         ...        ...  \n",
       "3861     2.3712     2.3712     2.3712     2.3712      2.3712    healthy  \n",
       "3862     2.3065     2.3065     2.3065     2.3065      2.3065    healthy  \n",
       "3863     2.2552     2.2552     2.2552     2.2552      2.2552    healthy  \n",
       "3864     2.2466     2.2466     2.2466     2.2466      2.2466    healthy  \n",
       "3865     2.2894     2.2894     2.2894     2.2894      2.2894    healthy  \n",
       "\n",
       "[3866 rows x 1001 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"combined_reshaped_data.csv\")\n",
    "# Convert labels to binary classes\n",
    "df['Label'] = df['Label'].apply(lambda x: 'healthy' if x == 'healthy' else 'unhealthy')\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df['Label'].values\n",
    "\n",
    "# Now 'healthy' is represented as 'healthy' and all other labels as 'unhealthy'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f975508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6925064599483204\n",
      "Precision: 0.9942418426103646\n",
      "Recall: 0.6879150066401063\n",
      "F1 Score: 0.8131868131868133\n",
      "Sensitivity: 0.6879150066401063\n",
      "Specificity: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "#binary class naïve bayes\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def calculate_statistics(X, y):\n",
    "    class_stats = {}\n",
    "    unique_classes = np.unique(y)\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        class_data = X[y == cls]\n",
    "        mean = np.mean(class_data, axis=0)\n",
    "        std = np.std(class_data, axis=0)\n",
    "        class_stats[cls] = {'mean': mean, 'std': std}\n",
    "        \n",
    "    return class_stats\n",
    "\n",
    "def calculate_probability(x, mean, std):\n",
    "    exponent = np.exp(-((x - mean)**2) / (2 * std**2))\n",
    "    return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
    "\n",
    "def predict_class(example, class_stats):\n",
    "    probabilities = {}\n",
    "    \n",
    "    for cls, stats in class_stats.items():\n",
    "        probabilities[cls] = 1\n",
    "        for i in range(len(stats['mean'])):\n",
    "            mean = stats['mean'][i]\n",
    "            std = stats['std'][i]\n",
    "            x = example[i]\n",
    "            probabilities[cls] *= calculate_probability(x, mean, std)\n",
    "            \n",
    "    return max(probabilities, key=probabilities.get)\n",
    "\n",
    "# Function to train the Naive Bayes model\n",
    "def train_naive_bayes(X_train, y_train):\n",
    "    class_stats = calculate_statistics(X_train, y_train)\n",
    "    return class_stats\n",
    "\n",
    "# Function to make predictions on the test set\n",
    "def predict_naive_bayes(X_test, class_stats):\n",
    "    predictions = [predict_class(example, class_stats) for example in X_test]\n",
    "    return predictions\n",
    "\n",
    "# Train the model\n",
    "class_stats = train_naive_bayes(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = predict_naive_bayes(X_test, class_stats)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, pos_label='unhealthy', average='binary')\n",
    "recall = recall_score(y_test, predictions, pos_label='unhealthy', average='binary')\n",
    "f1 = f1_score(y_test, predictions, pos_label='unhealthy', average='binary')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions, labels=['healthy', 'unhealthy'])\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2445abae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5675116399379203\n",
      "Precision: 0.9736487176281253\n",
      "Recall: 0.5675116399379203\n",
      "F1 Score: 0.7099315183544953\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "#binary class SVM\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.01, lambda_param=0.01, n_iterations=500):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient Descent\n",
    "        for _ in range(self.n_iterations):\n",
    "            for idx, x in enumerate(X):\n",
    "                condition = y_[idx] * (np.dot(x, self.weights) - self.bias) >= 1\n",
    "                if condition:\n",
    "                    self.weights -= self.learning_rate * (2 * self.lambda_param * self.weights)\n",
    "                else:\n",
    "                    self.weights -= self.learning_rate * (2 * self.lambda_param * self.weights - np.dot(x, y_[idx]))\n",
    "                    self.bias -= self.learning_rate * y_[idx]\n",
    "\n",
    "                \n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) - self.bias\n",
    "        return np.sign(linear_output)\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "label_dict = {label: i for i, label in enumerate(np.unique(y))}\n",
    "y_numeric = np.array([label_dict[label] for label in y])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "svm_model = SVM()\n",
    "svm_model.fit(X_scaled, y_numeric)\n",
    "\n",
    "# Make predictions\n",
    "predictions = svm_model.predict(X_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_numeric, predictions)\n",
    "precision = precision_score(y_numeric, predictions, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_numeric, predictions, average='weighted', zero_division=1) \n",
    "f1 = f1_score(y_numeric, predictions, average='weighted', zero_division=1) \n",
    "\n",
    "conf_matrix = confusion_matrix(y_numeric, predictions)\n",
    "\n",
    "tn, fp, fn, tp = conf_matrix.ravel()[:4]\n",
    "\n",
    "if (tn + fp) != 0:\n",
    "    specificity = tn / (tn + fp)\n",
    "else:\n",
    "    specificity = 0.0\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ef9065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Measures:\n",
      "accuracy: 0.07235142118863049\n",
      "precision: 0.03496985357450474\n",
      "recall: 0.07235142118863049\n",
      "f1: 0.04715036437011875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asfam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\asfam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#multiclass naive bayes\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.parameters = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.parameters[c] = {\n",
    "                'mean': X_c.mean(axis=0),\n",
    "                'std': X_c.std(axis=0) + 1e-10  # Adding a small constant to avoid division by zero\n",
    "            }\n",
    "        # Calculate priors based on the training data\n",
    "        self.priors = {c: len(X[y == c]) / len(X) for c in self.classes}\n",
    "\n",
    "    def _pdf(self, X, mean, std):\n",
    "        return np.exp(-0.5 * ((X - mean) / std) ** 2) / (np.sqrt(2 * np.pi) * std)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            posteriors = []\n",
    "            for c in self.classes:\n",
    "                likelihood = np.prod(self._pdf(x, self.parameters[c]['mean'], self.parameters[c]['std']))\n",
    "                # Use the pre-calculated priors instead of recalculating them in the predict method\n",
    "                prior = self.priors[c]\n",
    "                posterior = prior * likelihood\n",
    "                posteriors.append(posterior)\n",
    "            predictions.append(self.classes[np.argmax(posteriors)])\n",
    "        return np.array(predictions)\n",
    "\n",
    "def calculate_measures(y_true, y_pred):\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X = df1.iloc[:, :-1].values\n",
    "y = df1.iloc[:, -1].values\n",
    "\n",
    "# Train-test split\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(X))\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Create and train the Naive Bayes model\n",
    "nb_model = NaiveBayes()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Calculate classification measures\n",
    "measures = calculate_measures(y_test, predictions)\n",
    "print(\"Classification Measures:\")\n",
    "for key, value in measures.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e308a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asfam\\AppData\\Local\\Temp\\ipykernel_2316\\1899411782.py:29: RuntimeWarning: invalid value encountered in subtract\n",
      "  self.weights[c] -= self.learning_rate * (gradient + self.lambda_param * self.weights[c])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Measures:\n",
      "accuracy: 0.09560723514211886\n",
      "precision: 0.006829088224436179\n",
      "recall: 0.0714285714284749\n",
      "f1: 0.012466307276487247\n"
     ]
    }
   ],
   "source": [
    "#multiclass SVM\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MulticlassSVM:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000, lambda_param=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.lambda_param = lambda_param\n",
    "        self.weights = None\n",
    "        self.classes = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Ensure y contains integer class labels\n",
    "        le = LabelEncoder()\n",
    "        y_encoded = le.fit_transform(y)\n",
    "        self.classes = np.unique(y_encoded)\n",
    "        num_classes = len(self.classes)\n",
    "        num_features = X.shape[1]\n",
    "        self.weights = np.zeros((num_classes, num_features))\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for c in self.classes:\n",
    "                y_binary = np.where(y_encoded == c, 1, -1)\n",
    "                hinge_loss = 1 - y_binary * np.dot(X, self.weights[c])\n",
    "                hinge_loss[hinge_loss < 0] = 0  # max(0, hinge_loss)\n",
    "\n",
    "                gradient = -np.dot(hinge_loss * y_binary, X) / len(y_encoded)\n",
    "                self.weights[c] -= self.learning_rate * (gradient + self.lambda_param * self.weights[c])\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = np.dot(X, self.weights.T)\n",
    "        predictions = np.argmax(scores, axis=1)\n",
    "        return predictions\n",
    "\n",
    "def calculate_measures(y_true, y_pred):\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    precision = np.zeros(len(np.unique(y_true)))\n",
    "    recall = np.zeros(len(np.unique(y_true)))\n",
    "    f1 = np.zeros(len(np.unique(y_true)))\n",
    "\n",
    "    for i, c in enumerate(np.unique(y_true)):\n",
    "        true_positives = np.sum((y_true == c) & (y_pred == c))\n",
    "        false_positives = np.sum((y_true != c) & (y_pred == c))\n",
    "        false_negatives = np.sum((y_true == c) & (y_pred != c))\n",
    "\n",
    "        precision[i] = true_positives / (true_positives + false_positives + 1e-10)\n",
    "        recall[i] = true_positives / (true_positives + false_negatives + 1e-10)\n",
    "        f1[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i] + 1e-10)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": np.mean(precision),\n",
    "        \"recall\": np.mean(recall),\n",
    "        \"f1\": np.mean(f1)\n",
    "    }\n",
    "\n",
    "# Assuming df1 is your DataFrame\n",
    "X = df1.iloc[:, :-1].values\n",
    "y = df1.iloc[:, -1].values\n",
    "\n",
    "# Encode class labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Multiclass SVM model\n",
    "svm_model = MulticlassSVM()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate classification measures\n",
    "measures = calculate_measures(y_test, predictions)\n",
    "print(\"Classification Measures:\")\n",
    "for key, value in measures.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d8033f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ad876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80931f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc836c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd4fc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190197e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197d195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a59f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01959f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71154a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96280807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# Select only the columns containing numeric data for distance calculation (excluding 'Label')\n",
    "numeric_columns = combined_reshaped_data.columns[1:-1]\n",
    "\n",
    "# Extract the numeric data for distance calculation\n",
    "numeric_data = combined_reshaped_data[numeric_columns].values\n",
    "\n",
    "# Calculate the Euclidean distance matrix\n",
    "euclidean_distance_matrix = distance.cdist(numeric_data, numeric_data, 'euclidean')\n",
    "\n",
    "# Create a DataFrame from the distance matrix\n",
    "euclidean_distance_df = pd.DataFrame(euclidean_distance_matrix, columns=combined_reshaped_data['Label'], index=combined_reshaped_data['Label'])\n",
    "\n",
    "# Save the Euclidean distance DataFrame to a new CSV file\n",
    "output_file_path_distance = r'C:\\Users\\asfam\\OneDrive\\Desktop\\ml assignment\\euclidean_distance_matrix.csv'\n",
    "euclidean_distance_df.to_csv(output_file_path_distance)\n",
    "\n",
    "# Display the Euclidean distance DataFrame\n",
    "print(euclidean_distance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce186efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
